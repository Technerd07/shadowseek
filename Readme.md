Here is a detailed `README.md` for your `shadowseek` private search engine project, tailored to your folder structure and functionality:

---

```markdown
# ğŸ•µï¸â€â™‚ï¸ ShadowSeek â€” A Private Command-Line Search Engine

> "Search the web â€” public or private â€” with no ads, no tracking, no cookies, no compromises."

---

## ğŸ“Œ Overview

**ShadowSeek** is a privacy-focused, command-line-based search engine built in **pure Java**. It allows users to:

- Crawl public websites (and optionally `.onion` sites via Tor).
- Save and sanitize web content and links locally.
- Perform keyword-based searches on previously crawled content.
- Log search history securely (if needed).
- Run completely offline after crawling.

---

## ğŸ—‚ï¸ Project Structure

```

shadowseek/
â”œâ”€â”€ input\_urls/
â”‚   â””â”€â”€ input\_urls.txt       # List of URLs to crawl
â”œâ”€â”€ lib/
â”‚   â””â”€â”€ jsoup-1.16.1.jar     # HTML parsing library (Jsoup)
â”œâ”€â”€ logs/
â”‚   â””â”€â”€ search\_history.txt   # Search history logs
â”œâ”€â”€ pages/
â”‚   â”œâ”€â”€ ...\_content.txt      # Saved and cleaned HTML content
â”‚   â””â”€â”€ ...\_links.txt        # Extracted links from each page
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ WebCrawler.java      # Java crawler that downloads and parses content
â”‚   â”œâ”€â”€ PageSaver.java       # Helper class to save page content/links
â”‚   â””â”€â”€ CLIQuerySearch.java  # Search interface
â””â”€â”€ README.md

````

---

## âš™ï¸ Features

- âœ… **Offline Keyword Search**
- ğŸ” **No cookies, no tracking, no IP logging**
- ğŸŒ **Crawl public and deep web content** (`.onion` via Tor)
- ğŸ§¾ **Lightweight Search History Logging**
- ğŸ“„ **HTML Sanitization using Jsoup**

---

## ğŸš€ Setup Instructions

### 1. ğŸ”§ Requirements

- Java 11+ installed
- [Jsoup library](https://jsoup.org/download) (already included in `lib/`)

### 2. ğŸ§ª Compile the Code

```bash
javac -cp "lib/jsoup-1.16.1.jar" -d bin src/*.java
````

### 3. ğŸŒ Crawl URLs (with or without Tor)

Make sure your URLs are in `input_urls/input_urls.txt`, then:

```bash
# Normal crawl
java -cp "bin:lib/jsoup-1.16.1.jar" WebCrawler

# Or via Tor
torsocks java -cp "bin:lib/jsoup-1.16.1.jar" WebCrawler
```

### 4. ğŸ” Run the Search Engine

```bash
java -cp "bin:lib/jsoup-1.16.1.jar" CLIQuerySearch
```

---

## ğŸ“˜ Example Use Case

**1. Add URLs to Crawl**
Edit `input_urls/input_urls.txt`:

```txt
https://www.wikihow.com/Cook-Rice
https://www.thehindu.com
https://unherd.com
```

**2. Run Crawler**
This downloads HTML, extracts text/links, and stores them in `pages/`.

**3. Search Something**

```bash
Enter search query: india
```

**4. Output Example**:

```
ğŸ”¹ Match #1
File: https_thehindu_com_content.txt
Snippet: ... India election results updated live coverage...
```

---

## ğŸ”’ Privacy Features

| Feature                  | Status |
| ------------------------ | ------ |
| No cookies               | âœ…      |
| No IP logging            | âœ…      |
| User-Agent spoofing      | âœ…      |
| Optional Tor support     | âœ…      |
| No system fingerprinting | âœ…      |
| Logs saved locally only  | âœ…      |

---

## ğŸ› ï¸ Customization

* ğŸ” Modify `input_urls.txt` to crawl new sites.
* ğŸ“ Search logs are saved in `logs/search_history.txt`.
* ğŸ§½ Improve sanitization in `CLIQuerySearch.java` using Jsoup's `.text()` method.
* ğŸŒ Enable `.onion` support by configuring Tor and using `torsocks`.

---

## ğŸ“š Libraries Used

* [`jsoup`](https://jsoup.org) â€“ Java HTML Parser for sanitizing content.

---

## ğŸ§  Future Enhancements

* [ ] Result ranking based on frequency
* [ ] Export search results as PDFs
* [ ] Add support for Boolean operators (`AND`, `OR`, etc.)
* [ ] GUI wrapper for CLI

---

## ğŸ¤ Educational Purpose Disclaimer

This project is built strictly for **educational** and **placement preparation** use. Crawling `.onion` sites or bypassing access controls should only be done in safe, ethical, and legal environments.

---
